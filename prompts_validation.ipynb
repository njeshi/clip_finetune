{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce521d0f-b3bc-41df-930e-1bbe37bcbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "from clip.simple_tokenizer import SimpleTokenizer\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from src import FoodDataset\n",
    "from src import TextTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44232fbd-094e-4c00-8d88-a7f9b152f373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "clip_backbone = \"ViT-B/32\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, image_transform = clip.load(clip_backbone, jit=False)\n",
    "model = model.to(dtype=torch.float32)\n",
    "\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5be55c76-7c55-4f47-a00b-640b78db8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate templates to test\n",
    "templates = [\n",
    "    'a photo of {}, a type of food.',\n",
    "    'a cropped photo of the {}, a type of food.',\n",
    "    'a close-up photo of a {}, a type of food.',\n",
    "    'a photo of a delicious {}, a type of food.',\n",
    "    'a photo of the small {}, a type of food.',\n",
    "    'a photo of the large {}, a type of food.',\n",
    "]\n",
    "\n",
    "tokenizer = SimpleTokenizer()\n",
    "text_transformers = [TextTransformer(tokenizer, [template], context_length) for template in templates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c12756c-9928-4e46-956c-b42cf2ac5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"data/food-101/images\"\n",
    "dataloaders = [\n",
    "    DataLoader(FoodDataset(f'{dataset_root}', \n",
    "                           image_transform = image_transform,\n",
    "                           prompt_transform = text_transformer,\n",
    "                           return_indices=False), \n",
    "               batch_size=32, \n",
    "               shuffle=True) \n",
    "    for text_transformer in text_transformers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1acb6c11-3993-4326-8ba5-3472b8d7fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80970a8b-cdc9-4477-a91e-96e8b5ea515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tops1 = []\n",
    "    tops5 = []\n",
    "    for template_id, loader in enumerate(dataloaders):\n",
    "        top1, top5, n = 0., 0., 0.\n",
    "        for i, (images, text) in enumerate(tqdm(loader)):\n",
    "            images = images.to(device)\n",
    "            text = text[:,0,:]\n",
    "            text = text.to(device)\n",
    "            target = torch.arange(len(images), device=device)\n",
    "\n",
    "            image_features = model.visual(images)\n",
    "            text_features = model.encode_text(text)\n",
    "\n",
    "            # normalize features\n",
    "            image_features = image_features / (image_features.norm(dim=-1, keepdim=True) + 1e-6)\n",
    "            text_features = text_features / (text_features.norm(dim=-1, keepdim=True) + 1e-6)\n",
    "\n",
    "            logits = 100. * image_features @ text_features.T\n",
    "\n",
    "            # measure accuracy\n",
    "            acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
    "            top1 += acc1\n",
    "            top5 += acc5\n",
    "            n += images.size(0)\n",
    "\n",
    "        tops1.append((top1 / n) * 100)\n",
    "        tops5.append((top5 / n) * 100)\n",
    "\n",
    "    print(f'Template: {template_id}')\n",
    "    print(f\"Top-1 accuracy: {tops1[-1]:.2f}\")\n",
    "    print(f\"Top-5 accuracy: {tops5[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a85e0-c1eb-4d6e-b72e-a0a746582c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sorted_templates = [(templates[i], tops1[i], tops5[i]) for i in np.argsort(tops1)[::-1]]\n",
    "df_templates = pd.DataFrame(sorted_templates, \n",
    "                            index=np.arange(1, len(sorted_templates)+1),\n",
    "                            columns=['Template', 'Top-1 Accuracy', 'Top-5 Accuracy'])\n",
    "\n",
    "df_templates.to_csv(\"templates_score.csv\", index=False)\n",
    "df_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6125d663-7f60-4299-9fec-f98f8c609f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Template</th>\n",
       "      <th>Top-1 Accuracy</th>\n",
       "      <th>Top-5 Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a photo of a delicious {}, a type of food.</td>\n",
       "      <td>78.173267</td>\n",
       "      <td>98.625743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a photo of {}, a type of food.</td>\n",
       "      <td>78.109901</td>\n",
       "      <td>98.582178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a close-up photo of a {}, a type of food.</td>\n",
       "      <td>78.005941</td>\n",
       "      <td>98.526733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a photo of a tasty {}, a type of food.</td>\n",
       "      <td>77.959406</td>\n",
       "      <td>98.652475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a cropped photo of the {}, a type of food.</td>\n",
       "      <td>77.893069</td>\n",
       "      <td>98.595050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a photo of the small {}, a type of food.</td>\n",
       "      <td>77.543564</td>\n",
       "      <td>98.565347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a photo of the large {}, a type of food.</td>\n",
       "      <td>76.593069</td>\n",
       "      <td>98.427723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Template  Top-1 Accuracy  Top-5 Accuracy\n",
       "0  a photo of a delicious {}, a type of food.       78.173267       98.625743\n",
       "1              a photo of {}, a type of food.       78.109901       98.582178\n",
       "2   a close-up photo of a {}, a type of food.       78.005941       98.526733\n",
       "3      a photo of a tasty {}, a type of food.       77.959406       98.652475\n",
       "4  a cropped photo of the {}, a type of food.       77.893069       98.595050\n",
       "5    a photo of the small {}, a type of food.       77.543564       98.565347\n",
       "6    a photo of the large {}, a type of food.       76.593069       98.427723"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"templates_score.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c11268-51f0-4ef2-af36-22bf7104a013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
